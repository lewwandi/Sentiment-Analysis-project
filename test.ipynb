{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0b26e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder,label_binarize,StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2,SelectPercentile\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gc\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef798e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_sample_data(sample_size=20000):\n",
    "    splits = {'train': 'train_df.csv', 'validation': 'val_df.csv', 'test': 'test_df.csv'}\n",
    "    dfs = {}\n",
    "    for split, file in splits.items():\n",
    "        df = pd.read_csv(\"hf://datasets/Sp1786/multiclass-sentiment-analysis-dataset/\" + file)\n",
    "        print(f\"Original {split} dataset size: {len(df)}\")\n",
    "        if len(df) > sample_size:\n",
    "            df = df.sample(n=sample_size, random_state=42)\n",
    "            print(f\"Sampled {split} to {len(df)} rows for faster training\")\n",
    "        dfs[split] = df\n",
    "    return dfs['train'], dfs['validation'], dfs['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b73b8a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset size: 31232\n",
      "Sampled train to 20000 rows for faster training\n",
      "Original validation dataset size: 5205\n",
      "Original test dataset size: 5206\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = load_and_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dee3408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlation_matrix(df, title):\n",
    "    # Create numerical features\n",
    "    df_features = pd.DataFrame()\n",
    "    df_features['text_length'] = df['text'].apply(len)\n",
    "    df_features['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "    df_features['unique_words'] = df['text'].apply(lambda x: len(set(x.split())))\n",
    "    \n",
    "    # Encode sentiment labels numerically\n",
    "    le = LabelEncoder()\n",
    "    df_features['sentiment_encoded'] = le.fit_transform(df['sentiment'])\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df_features.corr()\n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bfde25f6",
   "metadata": {},
   "source": [
    "\n",
    "create_correlation_matrix(train_df, \"Correlation Matrix Before Preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de2f73e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4949a3c5",
   "metadata": {},
   
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed722082",
   "metadata": {},
   
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "79d38a1f",
   "metadata": {},
   "source": [
    "def text_preprocessing(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Handle contractions better\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "    text = re.sub(r\"'ve\", \" have\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"'d\", \" would\", text)\n",
    "    text = re.sub(r\"'m\", \" am\", text)\n",
    "    \n",
    "    # Remove URLs, HTML tags, and email addresses\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Handle repeated characters (e.g., \"sooo good\" -> \"so good\")\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Remove numbers but keep emoticons\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # # Keep some punctuation that might be important for sentiment\n",
    "    text = re.sub(r'[^\\w\\s!?]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c2c6d27",
   "metadata": {},
  
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\", download_dir=\"D:/7th SEMESTER/Machine Learning/modelnew/nltk_data\")\n",
    "with open('nltk_data/corpora/stopwords/english', 'r') as file:\n",
    "    stopwords = set(file.read().splitlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc1e97db",
   "metadata": {},
   "source": [
    "# Check class distribution\n",
    "print(\"\\nClass distribution in training data:\")\n",
    "print(train_df['sentiment'].value_counts())\n",
    "print(f\"\\nClass distribution percentages:\")\n",
    "print(train_df['sentiment'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f01f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(y_true, y_pred, classes, model_name):\n",
    "    \"\"\"Plot ROC curves for multiclass classification\"\"\"\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    n_classes = y_true_bin.shape[1]\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:0.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves for {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4de25a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, model_name):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f7b764b",
   "metadata": {},
    }
   ],
   "source": [
    "x_train = train_df[\"text\"]\n",
    "y_train = train_df[\"sentiment\"]\n",
    "x_val = val_df[\"text\"]\n",
    "y_val = val_df[\"sentiment\"]\n",
    "x_test = test_df[\"text\"]\n",
    "y_test = test_df[\"sentiment\"]\n",
    "\n",
    "print(f\"Training set: {x_train.shape}, Test set: {x_test.shape}, Validation set: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9cc9c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer():\n",
    "    return TfidfVectorizer(\n",
    "        max_features=8000,        # Increased features\n",
    "        min_df=10,                  # Reduced min_df for more features\n",
    "        max_df=0.7,               # Slightly increased max_df\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),        # Include trigrams\n",
    "        sublinear_tf=True,         # Apply sublinear tf scaling\n",
    "        norm='l2',\n",
    "        use_idf=True,\n",
    "        smooth_idf=True,\n",
    "        lowercase=True,\n",
    "        token_pattern=r'[a-zA-Z]{3,}',\n",
    "        binary=False,              \n",
    "        strip_accents='unicode'\n",
    "    )\n",
    "\n",
    "tfidf_vec = create_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2a55cc0",
   "metadata": {},
   "source": [
    "counts = y_train.value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(counts.values, labels=counts.index, autopct='%1.1f%%')\n",
    "plt.title('Distribution of Sentiment Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "433d97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detailed_scores(y_true, y_pred, dataset_name=\"Dataset\"):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'\\n{dataset_name} Scores:')\n",
    "    print(f'  Accuracy: {acc:.4f}')\n",
    "    print(f'  Weighted F1: {f1_weighted:.4f}')\n",
    "    print(f'  Macro F1: {f1_macro:.4f}')\n",
    "    print(f'  Precision: {precision:.4f}')\n",
    "    print(f'  Recall: {recall:.4f}')\n",
    "    \n",
    "    return acc, f1_weighted, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44ca0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_pipeline():\n",
    "    \"\"\"Create a pipeline for feature processing with dimensionality reduction\"\"\"\n",
    "    return Pipeline([\n",
    "        ('feature_selection', SelectPercentile(chi2, percentile=80)),  # Keep top 80% of features\n",
    "        ('svd', TruncatedSVD(n_components=2000, random_state=42)),     # Dimensionality reduction\n",
    "        ('scaler', StandardScaler())                                   # Standardize features\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be725b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_models(x_train, x_val, x_test, y_train, y_val, y_test):\n",
    "\n",
    "\n",
    "    print(\"Applying text preprocessing...\")\n",
    "    x_train_processed = [text_preprocessing(text) for text in x_train]\n",
    "    x_val_processed = [text_preprocessing(text) for text in x_val]\n",
    "    x_test_processed = [text_preprocessing(text) for text in x_test]\n",
    "\n",
    "    # Vectorize processed text\n",
    "    tfidf_vec = create_vectorizer()\n",
    "    x_train_vectorized = tfidf_vec.fit_transform(x_train_processed)\n",
    "    x_val_vectorized = tfidf_vec.transform(x_val_processed)\n",
    "    x_test_vectorized = tfidf_vec.transform(x_test_processed)\n",
    "\n",
    "\n",
    "    # Initialize and fit LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_val_encoded = label_encoder.transform(y_val)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "    print(\"Applying  feature selection...\")\n",
    "    feature_pipeline = create_feature_pipeline()\n",
    "    x_train_processed_features = feature_pipeline.fit_transform(x_train_vectorized, y_train_encoded)\n",
    "    x_val_processed_features = feature_pipeline.transform(x_val_vectorized)\n",
    "    x_test_processed_features = feature_pipeline.transform(x_test_vectorized)\n",
    "\n",
    "    # Use stratified k-fold for better validation\n",
    "    cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    \n",
    "    models = {\n",
    "        'Regularized Logistic Regression': {\n",
    "            'model': LogisticRegression(\n",
    "                random_state=42, \n",
    "                max_iter=1000,\n",
    "                class_weight='balanced',\n",
    "                #solver='liblinear',\n",
    "                fit_intercept=True,\n",
    "                multi_class='multinomial'\n",
    "            ),\n",
    "            'params': {\n",
    "                'C': [0.0001, 0.001, 0.01],  # Stronger regularization\n",
    "                'penalty': [ 'l2'],   # Try both L1 and L2\n",
    "            }\n",
    "        },\n",
    "        'Regularized Linear SVM': {\n",
    "            'model': LinearSVC(\n",
    "                random_state=42, \n",
    "                max_iter=2000,\n",
    "                class_weight='balanced',\n",
    "                dual=False,\n",
    "            ),\n",
    "            'params': {\n",
    "                'C': [0.0001, 0.001, 0.01],  # Stronger regularization\n",
    "                'penalty': ['l2'],\n",
    "                'loss': ['hinge', 'squared_hinge']\n",
    "            }\n",
    "        },\n",
    "        'Regularized Random Forest': {\n",
    "            'model': RandomForestClassifier(\n",
    "                random_state=42, \n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1,\n",
    "                bootstrap=True,\n",
    "                oob_score=True,    \n",
    "            ),\n",
    "            'params': {\n",
    "                'n_estimators': [ 100],\n",
    "                'max_depth': [ 5],      # Reduced depth\n",
    "                'min_samples_split': [50], # Increased\n",
    "                'min_samples_leaf': [ 25],  # Increased\n",
    "                'max_features': ['sqrt', 'log2'],  # More restrictive\n",
    "                'max_samples': [0.6],\n",
    "                'min_impurity_decrease': [0.001]      # Bootstrap sampling ratio\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    classes = label_encoder.classes_\n",
    "    \n",
    "    \n",
    "    for name, config in models.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training {name}...\")\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            config['model'],\n",
    "            config['params'],\n",
    "            cv=cv_strategy,\n",
    "            scoring='f1_weighted',\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # # Fit the model\n",
    "        grid_search.fit(x_train_processed_features, y_train_encoded)\n",
    "        \n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = best_model.predict(x_train_processed_features)\n",
    "        y_val_pred = best_model.predict(x_val_processed_features)\n",
    "        y_test_pred = best_model.predict(x_test_processed_features)\n",
    "        \n",
    "        y_train_pred_decoded = label_encoder.inverse_transform(y_train_pred)\n",
    "        y_val_pred_decoded = label_encoder.inverse_transform(y_val_pred)\n",
    "        y_test_pred_decoded = label_encoder.inverse_transform(y_test_pred)\n",
    "        \n",
    "        # Calculate scores\n",
    "        train_acc, train_f1_w, train_f1_m = detailed_scores(y_train, y_train_pred_decoded, \"Training\")\n",
    "        test_acc, test_f1_w, test_f1_m = detailed_scores(y_test, y_test_pred_decoded, \"Test\")\n",
    "        \n",
    "        # Check for overfitting\n",
    "        overfitting_score = train_acc - test_acc\n",
    "        print(f\"\\nOverfitting Score (Train - Test): {overfitting_score:.4f}\")\n",
    "        if overfitting_score > 0.05:\n",
    "            print(\" WARNING: Model shows signs of overfitting!\")\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': best_model,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'cv_score': grid_search.best_score_,\n",
    "            'train_accuracy': train_acc,\n",
    "            'test_accuracy': test_acc,\n",
    "            'train_f1_weighted': train_f1_w,\n",
    "            'test_f1_weighted': test_f1_w,\n",
    "            'overfitting_score': overfitting_score,\n",
    "            'y_test_pred': y_test_pred_decoded\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Cross-validation Score: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_test_pred_decoded, classes, name)\n",
    "        plot_roc_curves(y_test, y_test_pred_decoded, classes,name)\n",
    "        \n",
    "       \n",
    "    \n",
    "    return results, label_encoder, tfidf_vec, feature_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67fbb1ac",
   "metadata": {},
   "source": [
    "results, label_encoder, tfidf_vec, create_feature_pipeline = train_multiple_models(\n",
    "        x_train, x_val, x_test, y_train, y_val, y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bdc1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86051f81",
   "metadata": {},
    }
   ],
   "source": [
    "best_model = max(results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "print(f\"\\nBest performing model: {best_model[0]} with {best_model[1]['test_accuracy']:.3f} accuracy\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51a70914",
   "metadata": {},
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)  # Fit with training labels\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fedfecc2",
   "metadata": {},
   "source": [
    "def predict_sentiment(text, vectorizer, model, label_encoder):\n",
    "    processed_text = text_preprocessing(text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    processed_features = create_feature_pipeline.transform(vectorized_text)\n",
    "    prediction_encoded = model.predict(processed_features)[0]  \n",
    "    prediction_decoded = label_encoder.inverse_transform([prediction_encoded])[0]  \n",
    "    return prediction_decoded\n",
    "\n",
    "\n",
    "best_model = max(results.items(), key=lambda x: x[1]['test_accuracy'])  # Select best model\n",
    "best_model_name = best_model[0]  \n",
    "best_model_obj = results[best_model_name]['model']  # Access model from dictionary\n",
    "example_text = \"great product\"  # Example text for prediction\n",
    "prediction = predict_sentiment(example_text, tfidf_vec, best_model_obj, label_encoder)\n",
    "print(f\"\\nExample prediction: '{example_text}' -> {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae3c3e81",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "def save_best_model(vectorizer, best_model_name, results):\n",
    "    if vectorizer is not None:\n",
    "        joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "        print(\"Vectorizer saved!\")\n",
    "\n",
    "    # if feature_pipeline is not None:\n",
    "    #     joblib.dump(feature_pipeline, 'feature_pipeline.pkl')\n",
    "    #     print(\"Feature pipeline saved!\")\n",
    "    \n",
    "    best_result = results[best_model_name]\n",
    "    filename = f'best_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "    joblib.dump(best_result['model'], filename)\n",
    "    print(f\"Best model '{best_model_name}' saved as {filename}\")\n",
    "\n",
    "\n",
    "# Save only the best model\n",
    "save_best_model(tfidf_vec, best_model[0], results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9fd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
